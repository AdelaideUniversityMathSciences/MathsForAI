# Week 2 notes, links and assignments

This week we are doing a recap of linear algebra, and in particular, seeing how to implement all that stuff in `PyTorch` on Colab.

### Agenda

1. Vector spaces
2. Inner products, norms, distances
3. Eigenvalues and vectors
4. Rank
5. Tensors
6. The Johnson-Lindenstrauss lemma and the curse of dimensionality

### Code to do in the workshop

The code for the workshop is in the GitHub: 
https://github.com/AdelaideUniversityMathSciences/MathsForAI/ 

There are a few bits to play with and these become the assignments:

+ basic_tensors.ipynb
+ Einstein.ipynb
+ Gaussian_Orthogonal_Ensemble.ipynb
+ timing.ipynb
+ nearest_neighbor.ipynb

### Assignments

There is a self-assessment exercise setup for you to test your understanding on paper. But the main exercises for this course will be implemented in code through Colab. 

1. Basic tensor calculations described in `basic_tensor.ipynb`
2. Reproduce (using colab and PyTorch) the contour plot of the different $L_p$ vector norms.
2. Test out the Python/Colab code-timing mechanism: `timing.ipynb` 
3. Do the Einstein summation notation worksheet: `Einstein.ipynb`
4. Use similar code to the GOE code to generate the Gaussian Unitary Ensemble (you'll have to do a little independent research to find out what that is) and look at the distributional properties of its eigenvalues.
5. Make sure you understand the nearest-neighbours code (we will be using this later in the course, so better to learn it now). 

We'll put a handin box on MyUni. Hand up completed worksheets. 



