# Week 9

*Tentative plan for 2023: include some content from Simon's Week 10 lectures from 2022 on deepness and convolution, to create some space later on for discussion of LLMs.*

This week we revisit compressive sensing, as a nice example of the optimisation + regularisation topics we've talked about previously. We also introduce convolution in the context of neural networks, to connect back to the start of the course, and also through to the next section on modern ML.

### Topics

1. Sparse representations
2. Compressive sensing
3. Convolutions
4. (if time) Sequence learning and RNNs

We'll play around with compressive_sensing_example.ipynb in the Code directory of this repo.

### Papers
- Importance of sparse encoding: https://openreview.net/forum?id=By4afoWO-B 
- A guide to convolution arithmetic for deep learning: https://arxiv.org/abs/1603.07285 
