# Week 9

This week is the last week of Module 2 on the mathematics of deep learning. We revisit compressive sensing, as a nice example of the optimisation + regularisation topics we've talked about in the past 2 weeks. We also introduce convolution in the context of neural networks, to connect back to Module 1, and also through to Module 3 on modern ML.

### Topics

1. Sparse representations
2. Compressive sensing
3. Convolutions
4. (if time) Sequence learning and RNNs

We'll play around with compressive_sensing_example.ipynb in the Code directory of this repo.

### Papers
- Importance of sparse encoding: https://openreview.net/forum?id=By4afoWO-B 
- A guide to convolution arithmetic for deep learning: https://arxiv.org/abs/1603.07285 
