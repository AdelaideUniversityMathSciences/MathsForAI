{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nearest_neighbor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP9eGIPVR8TPggI12q1NpYU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjorkjh1vHBQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (1.0,))])\n",
        "\n",
        "# Training and testing datasets.\n",
        "trainset = datasets.MNIST(\n",
        "    root='../data', train=True,\n",
        "    download=True, transform=transform)\n",
        "testset = datasets.MNIST(\n",
        "    root='../data', train=False,\n",
        "    download=True, transform=transform)"
      ],
      "metadata": {
        "id": "NSSr6MLxvMpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize an example.\n",
        "example = trainset[0]\n",
        "x, y = example\n",
        "plt.imshow(torch.squeeze(x))\n",
        "print(y)"
      ],
      "metadata": {
        "id": "HId1HmVevAfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of list comprehension.\n",
        "elems = [0, 1, 2, 3, 4, 5]\n",
        "[x ** 2 for x in elems]"
      ],
      "metadata": {
        "id": "Iy56m8J8vV3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_train = torch.stack([x for x, y in trainset])\n",
        "labels_train = torch.tensor([y for x, y in trainset])\n",
        "images_test = torch.stack([x for x, y in testset])\n",
        "labels_test = torch.tensor([y for x, y in testset])\n",
        "print('images_train:', images_train.shape)\n",
        "print('labels_train:', labels_train.shape)"
      ],
      "metadata": {
        "id": "DfDfICBdvS5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten last 3 dimensions to obtain a vector.\n",
        "x_train = torch.flatten(images_train, start_dim=-3)\n",
        "x_test = torch.flatten(images_test, start_dim=-3)\n",
        "print('x_train:', x_train.shape)\n",
        "print('x_test:', x_test.shape)"
      ],
      "metadata": {
        "id": "TVG2CTnFvZbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain 2-norm distance between each pair of examples.\n",
        "\n",
        "# Use identity\n",
        "#   |u - v|^2 = u'u - 2 u'v + v'v\n",
        "# to avoid constructing [n_train, n_test, n_feat] array.\n",
        "\n",
        "# Compute dot product between each pair of (train, test) examples.\n",
        "dot = torch.einsum('id,jd->ij', x_train, x_test)\n",
        "print(dot.shape)\n",
        "\n",
        "# This is equivalent to the following code (which is too slow):\n",
        "#\n",
        "# n_train = x_train.shape[0]\n",
        "# n_test = x_test.shape[0]\n",
        "# dot = torch.zeros([n_train, n_test])\n",
        "# for i in range(n_train):\n",
        "#   for j in range(n_test):\n",
        "#     dot[i, j] = torch.dot(x_train[i], x_train[j])"
      ],
      "metadata": {
        "id": "JKWskQ3nvh_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add an extra dimension such that norms align with dot.\n",
        "norm_train = torch.sum(x_train ** 2, dim=1).unsqueeze(dim=1)\n",
        "norm_test = torch.sum(x_test ** 2, dim=1).unsqueeze(dim=0)\n",
        "print('norm_train:', norm_train.shape)\n",
        "print('norm_test:', norm_test.shape)"
      ],
      "metadata": {
        "id": "DFdxC7J4wRIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dist_euc = norm_train + norm_test - 2 * dot\n",
        "print('dist_euc:', dist_euc.shape)"
      ],
      "metadata": {
        "id": "Eg0JDwj0wpaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find nearest neighbor for each testing example.\n",
        "index_nearest = torch.argmin(dist_euc, dim=0)\n",
        "# Take label of nearest training example as the prediction.\n",
        "pred = labels_train[index_nearest]\n",
        "\n",
        "# Check the accuracy of our predictions!\n",
        "torch.mean((pred == labels_test).float())"
      ],
      "metadata": {
        "id": "XUvUx2WrxxEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try taking majority of k nearest neighbors.\n",
        "k = 3\n",
        "_, index_neighbors = torch.topk(dist_euc, k, largest=False, dim=0)\n",
        "print('index_neighbors:', index_neighbors.shape)\n",
        "\n",
        "# Take sum over one-hot representation to obtain per-class counts.\n",
        "y_train = F.one_hot(labels_train).float()\n",
        "print('y_train:', y_train.shape)\n",
        "y_neighbors = y_train[index_neighbors]\n",
        "print('y_neighbors:', y_neighbors.shape)"
      ],
      "metadata": {
        "id": "3VgAxYVBzvLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freq_neighbors = torch.sum(y_neighbors, dim=0)\n",
        "print('freq_neighbors:', freq_neighbors.shape)"
      ],
      "metadata": {
        "id": "amgjlCLG11iW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take the most frequent class amongst neighbors as the prediction.\n",
        "\n",
        "# May be necessary to break ties. Add 0.5^i for the i-th nearest neighbor.\n",
        "weight = 0.5 ** (1 + torch.arange(k))\n",
        "print('weight:', weight)\n",
        "\n",
        "tie_break = torch.tensordot(weight, y_neighbors, dims=1)\n",
        "torch.max(tie_break)  # Should be < 1 to avoid overwhelming frequency."
      ],
      "metadata": {
        "id": "Fot-MJel2dxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = freq_neighbors + tie_break\n",
        "pred = torch.argmax(score, dim=1)\n",
        "\n",
        "# Check the accuracy of our predictions!\n",
        "torch.mean((pred == labels_test).float())"
      ],
      "metadata": {
        "id": "JpKBDPusLlc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Allow python to return memory to the system.\n",
        "del dot, dist_euc"
      ],
      "metadata": {
        "id": "75ta48iX67n3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Put it all together in a function.\n",
        "\n",
        "def predict_knn(x_train, y_train, x_test, k, chunk_size=1000):\n",
        "  # Use cat(map(f, split(x))) to avoid crashing kernel due to RAM usage.\n",
        "  # This is necessary to evaluate on the training set (60k examples).\n",
        "  # index_neighbors = find_neighbors(x_train, x_test, k)\n",
        "  index_neighbors = torch.cat([\n",
        "    find_neighbors(x_train, x, k)\n",
        "    for x in torch.split(x_test, chunk_size)\n",
        "  ], dim=1)\n",
        "  y_neighbors = y_train[index_neighbors]\n",
        "  freq_neighbors = torch.sum(y_neighbors, dim=0)\n",
        "  weight = 0.5 ** (1 + torch.arange(k))\n",
        "  tie_break = torch.tensordot(weight, y_neighbors, dims=1)\n",
        "  score = freq_neighbors + tie_break\n",
        "  return torch.argmax(score, dim=1)\n",
        "\n",
        "def find_neighbors(x_train, x_test, k):\n",
        "  dot = torch.einsum('id,jd->ij', x_train, x_test)\n",
        "  norm_train = torch.sum(x_train ** 2, dim=1).unsqueeze(dim=1)\n",
        "  norm_test = torch.sum(x_test ** 2, dim=1).unsqueeze(dim=0)\n",
        "  dist_euc = norm_train + norm_test - 2 * dot\n",
        "  _, neighbors = torch.topk(dist_euc, k, largest=False, sorted=True, dim=0)\n",
        "  return neighbors"
      ],
      "metadata": {
        "id": "uFYPwKza2oU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate nearest neighbor for varying k.\n",
        "\n",
        "for k in [1, 3, 10, 100]:\n",
        "  pred_test = predict_knn(x_train, y_train, x_test, k)\n",
        "  acc_test = torch.mean((pred_test == labels_test).float()).item()\n",
        "  print('k:', k)\n",
        "  print(f'test acc {acc_test:.2%}')\n",
        "  print()"
      ],
      "metadata": {
        "id": "S29r9Hz86XBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do the same thing for the training set (slow!!)\n",
        "\n",
        "for k in [1, 3, 5, 100]:\n",
        "  pred_train = predict_knn(x_train, y_train, x_train, k)\n",
        "  acc_train = torch.mean((pred_train == labels_train).float()).item()\n",
        "  print('k:', k)\n",
        "  print(f'train acc {acc_train:.2%}')\n",
        "  print()"
      ],
      "metadata": {
        "id": "VZl4ZuSGH_Lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eOuLv3U48FIi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}