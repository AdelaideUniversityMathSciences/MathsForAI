{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdelaideUniversityMathSciences/MathsForAI/blob/main/Code/compressive_sensing_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL2i4Vlkped9"
      },
      "source": [
        "# Compressive sensing example\n",
        "\n",
        "This is adapted from http://www.pyrunner.com/weblog/2016/05/26/compressed-sensing-python/, but does not work great in some ways. First, a simulated regression example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_C1hkP2OVfh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.optimize as spopt\n",
        "import scipy.fftpack as spfft\n",
        "import scipy.ndimage as spimg\n",
        "import cvxpy as cvx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rL9QVhn9OW9n"
      },
      "outputs": [],
      "source": [
        "# generate some data with noise\n",
        "x = np.sort(np.random.uniform(0, 10, 15))\n",
        "y = 3 + 0.2 * x + 0.1 * np.random.randn(len(x))\n",
        "\n",
        "# For you: plot the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBRlgxj7OcoE"
      },
      "outputs": [],
      "source": [
        "# find L1 line fit\n",
        "l1_fit = lambda x0, x, y: np.sum(np.abs(x0[0] * x + x0[1] - y))\n",
        "xopt1 = spopt.fmin(func=l1_fit, x0=[1, 1], args=(x, y))\n",
        "\n",
        "# find L2 line fit\n",
        "l2_fit = lambda x0, x, y: np.sum(np.power(x0[0] * x + x0[1] - y, 2))\n",
        "xopt2 = spopt.fmin(func=l2_fit, x0=[1, 1], args=(x, y))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhpl8vp8Ov-b"
      },
      "source": [
        "Exercises: \n",
        "- Plot the data and these regression fits. \n",
        "- Which is \"better\" and why?\n",
        "- Now, add some outliers to the data: include a point at say $(2,7)$, and another at $(9,2)$. Re-run the fitting and replot. \n",
        "- Which model performs better now, and why?\n",
        "\n",
        "## Compressive sensing for images example\n",
        "\n",
        "Here's the bit that doesn't work great, or at least works slow due to the constrained optimisation piece. Figure out where the constrained optimisation part is!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ai1tfgKGOc9O"
      },
      "outputs": [],
      "source": [
        "from skimage import io\n",
        "\n",
        "\n",
        "def dct2(x):\n",
        "    return spfft.dct(spfft.dct(x.T, norm='ortho', axis=0).T, norm='ortho', axis=0)\n",
        "\n",
        "def idct2(x):\n",
        "    return spfft.idct(spfft.idct(x.T, norm='ortho', axis=0).T, norm='ortho', axis=0)\n",
        "\n",
        "# read original image and downsize for speed\n",
        "# Xorig = spimg.imread(, flatten=True, mode='L') # read in grayscale\n",
        "Xorig = io.imread('https://upload.wikimedia.org/wikipedia/en/e/e8/Escher_Waterfall.jpg', as_gray = True)\n",
        "\n",
        "X = spimg.zoom(Xorig, 0.2)\n",
        "ny,nx = X.shape\n",
        "\n",
        "plt.imshow(Xorig)\n",
        "plt.title('Original')\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(X)\n",
        "plt.title('Downsized')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3E474jM8ioAJ"
      },
      "outputs": [],
      "source": [
        "# extract small sample of signal\n",
        "k = round(nx * ny * 0.5) # 50% sample\n",
        "ri = np.random.choice(nx * ny, k, replace=False) # random sample of indices\n",
        "b = X.T.flat[ri]\n",
        "b = np.expand_dims(b, axis=1).flatten()\n",
        "\n",
        "# create dct matrix operator using kron (memory errors for large ny*nx)\n",
        "A = np.kron(\n",
        "    spfft.idct(np.identity(nx), norm='ortho', axis=0),\n",
        "    spfft.idct(np.identity(ny), norm='ortho', axis=0)\n",
        "    )\n",
        "A = A[ri,:] # same as phi times kron\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72rajfOjrPVw"
      },
      "outputs": [],
      "source": [
        "# do L1 optimization\n",
        "vx = cvx.Variable(nx * ny)\n",
        "objective = cvx.Minimize(cvx.norm(vx, 1))\n",
        "constraints = [A @ vx == b]\n",
        "prob = cvx.Problem(objective, constraints)\n",
        "result = prob.solve(verbose=True)\n",
        "Xat2 = np.array(vx.value).squeeze()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98qIWKtCi7Uy"
      },
      "outputs": [],
      "source": [
        "# reconstruct signal\n",
        "Xat = Xat2.reshape(nx, ny).T # stack columns\n",
        "Xa = idct2(Xat)\n",
        "\n",
        "# confirm solution\n",
        "if not np.allclose(X.T.flat[ri], Xa.T.flat[ri]):\n",
        "    print('Warning: values at sample indices don\\'t match original.')\n",
        "\n",
        "# create images of mask (for visualization)\n",
        "mask = np.zeros(X.shape)\n",
        "mask.T.flat[ri] = 255\n",
        "Xm = 255 * np.ones(X.shape)\n",
        "Xm.T.flat[ri] = X.T.flat[ri]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_ge5Jq1j6uH"
      },
      "outputs": [],
      "source": [
        "plt.imshow(Xa)\n",
        "plt.title('Reconstructed image')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some clever people on the internet (thank you StackExchange https://stats.stackexchange.com/questions/62416/image-reconstruction-using-compressed-sensing) have drawn the parallel between compressive sensing and LASSO regression. I have had varied success with the following code -- see how you go running this, and we'll see if we can collaboratively fix it if necessary!\n",
        "\n",
        "If you can get it to work, experiment with using ridge regression instead of LASSO. (See the example below.) "
      ],
      "metadata": {
        "id": "1MrQdBOfEBZT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wIhG6DvtqMyv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.fftpack as spfft\n",
        "import scipy.ndimage as spimg\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "# read original image and downsize for speed\n",
        "Xorig = io.imread('https://upload.wikimedia.org/wikipedia/en/e/e8/Escher_Waterfall.jpg', as_gray = True)\n",
        "\n",
        "X = spimg.zoom(Xorig, 0.2)\n",
        "ny,nx = X.shape\n",
        "\n",
        "# extract small sample of signal\n",
        "k = round(nx * ny * 0.5) # 50% sample\n",
        "ri = np.random.choice(nx * ny, k, replace=False) # random sample of indices\n",
        "b = X.T.flat[ri]\n",
        "b = np.expand_dims(b, axis=1)\n",
        "\n",
        "# create dct matrix operator using kron (memory errors for large ny*nx)\n",
        "A = np.kron(\n",
        "    spfft.idct(np.identity(nx), norm='ortho', axis=0),\n",
        "    spfft.idct(np.identity(ny), norm='ortho', axis=0)\n",
        "    )\n",
        "A = A[ri,:] # same as phi times kron\n",
        "\n",
        "\n",
        "\n",
        "lasso = Lasso(alpha=0.001)\n",
        "lasso.fit(A, b)\n",
        "\n",
        "Xat = np.array(lasso.coef_).reshape(nx, ny).T # stack columns\n",
        "# Get the reconstructed image\n",
        "Xa = idct2(Xat)\n",
        "\n",
        "plt.imshow(Xa)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a less-fancy \"safety example\", a straight-from-the-can example from sklearn tutorials: https://scikit-learn.org/stable/auto_examples/applications/plot_tomography_l1_reconstruction.html\n",
        "\n",
        "Note the use of ridge regression (L2 norm) here as well as LASSO (L1 norm)!"
      ],
      "metadata": {
        "id": "BSisg1IGEofc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTq8Ovc2q5S2"
      },
      "outputs": [],
      "source": [
        "# Author: Emmanuelle Gouillart <emmanuelle.gouillart@nsup.org>\n",
        "# License: BSD 3 clause\n",
        "\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "from scipy import ndimage\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def _weights(x, dx=1, orig=0):\n",
        "    x = np.ravel(x)\n",
        "    floor_x = np.floor((x - orig) / dx).astype(np.int64)\n",
        "    alpha = (x - orig - floor_x * dx) / dx\n",
        "    return np.hstack((floor_x, floor_x + 1)), np.hstack((1 - alpha, alpha))\n",
        "\n",
        "\n",
        "def _generate_center_coordinates(l_x):\n",
        "    X, Y = np.mgrid[:l_x, :l_x].astype(np.float64)\n",
        "    center = l_x / 2.0\n",
        "    X += 0.5 - center\n",
        "    Y += 0.5 - center\n",
        "    return X, Y\n",
        "\n",
        "\n",
        "def build_projection_operator(l_x, n_dir):\n",
        "    \"\"\"Compute the tomography design matrix.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    l_x : int\n",
        "        linear size of image array\n",
        "\n",
        "    n_dir : int\n",
        "        number of angles at which projections are acquired.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    p : sparse matrix of shape (n_dir l_x, l_x**2)\n",
        "    \"\"\"\n",
        "    X, Y = _generate_center_coordinates(l_x)\n",
        "    angles = np.linspace(0, np.pi, n_dir, endpoint=False)\n",
        "    data_inds, weights, camera_inds = [], [], []\n",
        "    data_unravel_indices = np.arange(l_x ** 2)\n",
        "    data_unravel_indices = np.hstack((data_unravel_indices, data_unravel_indices))\n",
        "    for i, angle in enumerate(angles):\n",
        "        Xrot = np.cos(angle) * X - np.sin(angle) * Y\n",
        "        inds, w = _weights(Xrot, dx=1, orig=X.min())\n",
        "        mask = np.logical_and(inds >= 0, inds < l_x)\n",
        "        weights += list(w[mask])\n",
        "        camera_inds += list(inds[mask] + i * l_x)\n",
        "        data_inds += list(data_unravel_indices[mask])\n",
        "    proj_operator = sparse.coo_matrix((weights, (camera_inds, data_inds)))\n",
        "    return proj_operator\n",
        "\n",
        "\n",
        "def generate_synthetic_data():\n",
        "    \"\"\"Synthetic binary data\"\"\"\n",
        "    rs = np.random.RandomState(0)\n",
        "    n_pts = 36\n",
        "    x, y = np.ogrid[0:l, 0:l]\n",
        "    mask_outer = (x - l / 2.0) ** 2 + (y - l / 2.0) ** 2 < (l / 2.0) ** 2\n",
        "    mask = np.zeros((l, l))\n",
        "    points = l * rs.rand(2, n_pts)\n",
        "    mask[(points[0]).astype(int), (points[1]).astype(int)] = 1\n",
        "    mask = ndimage.gaussian_filter(mask, sigma=l / n_pts)\n",
        "    res = np.logical_and(mask > mask.mean(), mask_outer)\n",
        "    return np.logical_xor(res, ndimage.binary_erosion(res))\n",
        "\n",
        "\n",
        "# Generate synthetic images, and projections\n",
        "l = 128\n",
        "proj_operator = build_projection_operator(l, l // 7)\n",
        "data = generate_synthetic_data()\n",
        "proj = proj_operator @ data.ravel()[:, np.newaxis]\n",
        "proj += 0.15 * np.random.randn(*proj.shape)\n",
        "\n",
        "# Reconstruction with L2 (Ridge) penalization\n",
        "rgr_ridge = Ridge(alpha=0.2)\n",
        "rgr_ridge.fit(proj_operator, proj.ravel())\n",
        "rec_l2 = rgr_ridge.coef_.reshape(l, l)\n",
        "\n",
        "# Reconstruction with L1 (Lasso) penalization\n",
        "# the best value of alpha was determined using cross validation\n",
        "# with LassoCV\n",
        "rgr_lasso = Lasso(alpha=0.001)\n",
        "rgr_lasso.fit(proj_operator, proj.ravel())\n",
        "rec_l1 = rgr_lasso.coef_.reshape(l, l)\n",
        "\n",
        "plt.figure(figsize=(8, 3.3))\n",
        "plt.subplot(131)\n",
        "plt.imshow(data, cmap=plt.cm.gray, interpolation=\"nearest\")\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"original image\")\n",
        "plt.subplot(132)\n",
        "plt.imshow(rec_l2, cmap=plt.cm.gray, interpolation=\"nearest\")\n",
        "plt.title(\"L2 penalization\")\n",
        "plt.axis(\"off\")\n",
        "plt.subplot(133)\n",
        "plt.imshow(rec_l1, cmap=plt.cm.gray, interpolation=\"nearest\")\n",
        "plt.title(\"L1 penalization\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.subplots_adjust(hspace=0.01, wspace=0.01, top=1, bottom=0, left=0, right=1)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfcDMfyopLxR"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "compressive_sensing_example_1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOEj5oXorWenZlslmnjF77J",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}