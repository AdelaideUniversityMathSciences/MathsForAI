{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of assignment_nearest_neighbor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdelaideUniversityMathSciences/MathsForAI/blob/main/Code/Copy_of_assignment_nearest_neighbor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this sheet, we will investigate the effect of using different distance metrics for nearest neighbour classification.\n",
        "\n",
        "You may need to refer to the [PyTorch documentation](https://pytorch.org/docs/stable/index.html).\n",
        "It's good to familiarise yourself with the different modules so that you know which functions exist!"
      ],
      "metadata": {
        "id": "QLJgFpHyXkQA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjorkjh1vHBQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The MNIST handwritten character dataset may be too simple for our investigation.\n",
        "\n",
        "Modify the code below to use the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html), which contains low-resolution colour photos for 10 classes."
      ],
      "metadata": {
        "id": "FH-BRyXKXSYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=0.5, std=1.0)])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='../data', train=True,\n",
        "                               download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='../data', train=False,\n",
        "                              download=True, transform=transform)"
      ],
      "metadata": {
        "id": "NSSr6MLxvMpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construct large tensors that contain all images and labels in each set."
      ],
      "metadata": {
        "id": "FuvXCOMEabHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.stack([x for x, y in train_dataset])\n",
        "y_train = torch.tensor([y for x, y in train_dataset])\n",
        "x_test = torch.stack([x for x, y in test_dataset])\n",
        "y_test = torch.tensor([y for x, y in test_dataset])"
      ],
      "metadata": {
        "id": "DfDfICBdvS5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flatten the last 3 dimensions of each tensor to obtain vectors of dimension width\\*height\\*3."
      ],
      "metadata": {
        "id": "A6HFbwzDa2Dp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.flatten(x_train, start_dim=-3)\n",
        "x_test = torch.flatten(x_test, start_dim=-3)"
      ],
      "metadata": {
        "id": "TVG2CTnFvZbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now need to compute the distance between `x_test[i]` and `x_train[j]` for all (i, j).\n",
        "\n",
        "To do this, it is critical to understand \"broadcasting\", which functions the same in pytorch as in numpy.\n",
        "When we try to apply an element-wise operation to two arrays with different shapes, each array is implicitly repeated along any dimension which has length 1.\n",
        "For example, if we add a row vector and a column vector, we get a matrix:\n",
        "```python\n",
        ">>> x\n",
        "tensor([[1, 2, 3]])\n",
        ">>> y\n",
        "tensor([[10],\n",
        "        [20],\n",
        "        [30]])\n",
        ">>> x.shape\n",
        "torch.Size([1, 3])\n",
        ">>> y.shape\n",
        "torch.Size([3, 1])\n",
        ">>> x + y\n",
        "tensor([[11, 12, 13],\n",
        "        [21, 22, 23],\n",
        "        [31, 32, 33]])\n",
        "```\n",
        "If the two arrays are of a different order (`ndims`), then broadcasting starts at the last dimension and works backward (if you're familiar with Matlab, broadcasting starts at the first dimension and proceeds forward).\n",
        "Any missing dimensions are treated as length 1.\n",
        "Note that scalars have order 0.\n",
        "\n",
        "It's often useful to insert a dimension using `torch.unsqueeze()`.\n",
        "For example:\n",
        "```\n",
        ">>> x\n",
        "tensor([1, 2, 3])\n",
        ">>> y\n",
        "tensor([10, 20, 30])\n",
        ">>> x + torch.unsqueeze(y, 1)\n",
        "tensor([[11, 12, 13],\n",
        "        [21, 22, 23],\n",
        "        [31, 32, 33]])\n",
        "```\n",
        "It is not necessary to unsqueeze `x` because broadcasting starts at the last dimension and missing dimensions are treated as length 1.\n",
        "\n",
        "If you like, you can read more about broadcasting (in numpy) in [this guide](https://numpy.org/doc/stable/user/basics.broadcasting.html)."
      ],
      "metadata": {
        "id": "8y1IFD5GbN_i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could use broadcasting to obtain `x_train[i] - x_test[j]` as shown below.\n",
        "However, this will instantiate an array with shape `[n_train, n_test, width*height*3]`, which takes too much RAM to fit on the computer.\n",
        "(The following code will crash colab!)"
      ],
      "metadata": {
        "id": "elOoyC62f5Qt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# difference = torch.unsqueeze(x_train, 1) - torch.unsqueeze(x_test, 0)"
      ],
      "metadata": {
        "id": "yjKB0HUZbwCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead, we will use `einsum()` to obtain the dot product and then use broadcasting to compute\n",
        "\n",
        "$$\n",
        "\\|x_{i} - x_{j}\\|^2 = \\|x_{i}\\|^2 + \\|x_{j}\\|^2 - 2 \\langle x_{i}, x_{j} \\rangle\n",
        "$$\n",
        "\n",
        "(Technically this is the squared distance but this will have no impact on the ordering.)"
      ],
      "metadata": {
        "id": "2sp61oUGhb7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dot = torch.einsum('id,jd->ij', x_train, x_test)\n",
        "norm_train = torch.sum(x_train ** 2, dim=1)\n",
        "norm_test = torch.sum(x_test ** 2, dim=1)\n",
        "dist = (\n",
        "    torch.unsqueeze(norm_train, 1)\n",
        "    + torch.unsqueeze(norm_test, 0)\n",
        "    - 2 * dot)"
      ],
      "metadata": {
        "id": "Z5xLEhcojkNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each testing example, find the index of the nearest training example (arg min of distance).\n",
        "Use the label of that example as the prediction."
      ],
      "metadata": {
        "id": "kUIXcExHpjPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_nearest = torch.argmin(dist, dim=0)\n",
        "pred = y_train[index_nearest]"
      ],
      "metadata": {
        "id": "XUvUx2WrxxEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To measure the accuracy, we check if the prediction is equal to the label and take the mean after converting to a float (0 if not equal, 1 if equal)."
      ],
      "metadata": {
        "id": "pMXzBzldq983"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean((pred == y_test).float())"
      ],
      "metadata": {
        "id": "WRclNC15qzXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before proceeding, let's tell Python that we no longer need those large tensors.\n",
        "To do this, we simply set `dot` and `dist` to something else (in this case, to `None`).\n",
        "Python automatically returns memory to the system when it is no longer referenced by any variable."
      ],
      "metadata": {
        "id": "uNY0hRQYsmbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dot = None\n",
        "dist = None"
      ],
      "metadata": {
        "id": "pgOx7WBZsJTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your task is to fill in the functions below.\n",
        "First define a function that measures accuracy.\n",
        "It should return a scalar in [0, 1]."
      ],
      "metadata": {
        "id": "a9O8doiLsJlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(labels, pred):\n",
        "  ..."
      ],
      "metadata": {
        "id": "v2VqBNWFsQ_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now define each of the functions below using the L2 distance (as above), L1 distance, L-infinity distance and the [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) (L2 inner product after normalizing to unit norm, i.e. cosine of angle between vectors).\n",
        "\n",
        "For the purpose of this exercise, you are _not_ permitted to use `torch.cdist()` or any equivalent function (although it's a good function to know about).\n",
        "You should not use a `for` loop to iterate over the examples in either set."
      ],
      "metadata": {
        "id": "2pFS7gn4ueHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nearest_neighbor_l2(x_train, y_train, x_test):\n",
        "  ..."
      ],
      "metadata": {
        "id": "eOuLv3U48FIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nearest_neighbor_l1(x_train, y_train, x_test):\n",
        "  ..."
      ],
      "metadata": {
        "id": "eGbs0XA_uhgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nearest_neighbor_linf(x_train, y_train, x_test):\n",
        "  ..."
      ],
      "metadata": {
        "id": "YOwctWdKsfE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nearest_neighbor_cos(x_train, y_train, x_test):\n",
        "  ..."
      ],
      "metadata": {
        "id": "7BOly0Lcunuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After defining these functions, it should be possible to run the following.\n",
        "\n",
        "(We will take a random subset of 1000 examples to make it run faster and fit more easily into memory.)"
      ],
      "metadata": {
        "id": "ELOFv35wwI9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "subset_train = torch.randperm(len(train_dataset))[:1000]\n",
        "subset_test = torch.randperm(len(test_dataset))[:1000]\n",
        "\n",
        "x_train, y_train = x_train[subset_train], y_train[subset_train]\n",
        "x_test, y_test = x_test[subset_test], y_test[subset_test]"
      ],
      "metadata": {
        "id": "x3lyXLN_x6tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = nearest_neighbor_l2(x_train, y_train, x_test)\n",
        "compute_accuracy(y_test, pred)"
      ],
      "metadata": {
        "id": "4ogyvNx6v67i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = nearest_neighbor_l1(x_train, y_train, x_test)\n",
        "compute_accuracy(y_test, pred)"
      ],
      "metadata": {
        "id": "HksgKf_jwFc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = nearest_neighbor_linf(x_train, y_train, x_test)\n",
        "compute_accuracy(y_test, pred)"
      ],
      "metadata": {
        "id": "VKU31KVRwDSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = nearest_neighbor_cos(x_train, y_train, x_test)\n",
        "compute_accuracy(y_test, pred)"
      ],
      "metadata": {
        "id": "bGjbJgItwGWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Xu0T0iZ94BT7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}