# Generalisation week: Sources of error and regularisation in deep learning

### Pre-reading
Bishop & Bishop, [Deep Learning](https://www.bishopbook.com) Section 1.2 on overfitting.

### Topics

1. Sources of error in DL
2. Regularisation recap
3. Bias-variance
4. Regularisation in DL
5. Maths of dropout

We might play around with the dropout_example.ipynb in the Code directory of this repo.

### Papers
2 papers on dropout in this directory. The single linear activation example in the NeurIPS paper is particularly helpful to illustrate why dropout works.

Most of the examples etc otherwise are from Prince (2023) [Understanding Deep Learning](https://udlbook.github.io/udlbook/).
